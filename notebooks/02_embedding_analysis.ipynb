{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔍 Embedding Analysis & Visualization\n",
    "\n",
    "This notebook visualizes document embeddings to understand the semantic relationships between documents in our corpus. We'll explore:\n",
    "\n",
    "1. **Dimensionality Reduction** - Using t-SNE to visualize high-dimensional embeddings in 2D space\n",
    "2. **Similarity Heatmaps** - Visualizing query-document and document-document similarities\n",
    "3. **Cluster Analysis** - Identifying natural groupings in our document space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import umap\n",
    "\n",
    "# Add the src directory to the path\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.embedder import Embedder\n",
    "\n",
    "# Set paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "OUTPUT_DIR = Path(\"../outputs\")\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Documents and Generate Embeddings\n",
    "\n",
    "First, we'll load our processed documents and generate embeddings for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "# Load processed documents\n",
    "with open(PROCESSED_DIR / \"processed_chunks.json\", 'r') as f:\n",
    "    documents = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(documents)} document chunks\")\n",
    "\n",
    "# Initialize embedder\n",
    "embedder = Embedder()\n",
    "\n",
    "# Generate embeddings for all documents\n",
    "doc_texts = [doc['content'] for doc in documents]\n",
    "doc_embeddings = embedder.embed_documents(doc_texts)\n",
    "\n",
    "print(f\"Generated embeddings with shape: {doc_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dimensionality Reduction with t-SNE\n",
    "\n",
    "We'll use t-SNE to reduce our high-dimensional embeddings to 2D for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "# Apply t-SNE for dimensionality reduction\n",
    "tsne = TSNE(n_components=2, perplexity=15, random_state=42, n_iter=1000)\n",
    "embeddings_2d = tsne.fit_transform(doc_embeddings)\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "plot_df = pd.DataFrame({\n",
    "    'x': embeddings_2d[:, 0],\n",
    "    'y': embeddings_2d[:, 1],\n",
    "    'document_id': [doc['id'] for doc in documents],\n",
    "    'title': [doc['title'] for doc in documents],\n",
    "    'category': [doc['metadata'].get('category', 'unknown') for doc in documents],\n",
    "    'parent_id': [doc['metadata'].get('parent_id', doc['id']) for doc in documents]\n",
    "})\n",
    "\n",
    "# Plot t-SNE visualization colored by category\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.scatterplot(data=plot_df, x='x', y='y', hue='category', style='category', s=100, alpha=0.7)\n",
    "plt.title('t-SNE Visualization of Document Embeddings by Category', fontsize=16)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=12)\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add annotations for a few points (not all to avoid clutter)\n",
    "for i, row in plot_df.sample(min(10, len(plot_df))).iterrows():\n",
    "    plt.annotate(row['title'][:20] + '...', \n",
    "                 (row['x'], row['y']),\n",
    "                 xytext=(5, 5),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=8,\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"tsne_visualization.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Similarity Heatmap\n",
    "\n",
    "Let's visualize the similarity between documents to identify clusters and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "# Calculate cosine similarity between all document pairs\n",
    "similarity_matrix = cosine_similarity(doc_embeddings)\n",
    "\n",
    "# For visualization, let's use a subset of documents if there are too many\n",
    "max_docs_for_heatmap = 20\n",
    "if len(documents) > max_docs_for_heatmap:\n",
    "    # Sample documents from different categories for better visualization\n",
    "    categories = plot_df['category'].unique()\n",
    "    sampled_indices = []\n",
    "    \n",
    "    # Try to get an equal number from each category\n",
    "    docs_per_category = max(1, max_docs_for_heatmap // len(categories))\n",
    "    \n",
    "    for category in categories:\n",
    "        category_indices = plot_df[plot_df['category'] == category].index.tolist()\n",
    "        sampled_indices.extend(np.random.choice(category_indices, \n",
    "                                               size=min(docs_per_category, len(category_indices)),\n",
    "                                               replace=False))\n",
    "    \n",
    "    # If we still need more, sample randomly\n",
    "    if len(sampled_indices) < max_docs_for_heatmap:\n",
    "        remaining = list(set(range(len(documents))) - set(sampled_indices))\n",
    "        additional = np.random.choice(remaining, \n",
    "                                     size=min(max_docs_for_heatmap - len(sampled_indices), len(remaining)),\n",
    "                                     replace=False)\n",
    "        sampled_indices.extend(additional)\n",
    "else:\n",
    "    sampled_indices = range(len(documents))\n",
    "\n",
    "# Extract the subset for visualization\n",
    "subset_similarity = similarity_matrix[np.ix_(sampled_indices, sampled_indices)]\n",
    "subset_titles = [documents[i]['title'][:30] + '...' if len(documents[i]['title']) > 30 else documents[i]['title'] for i in sampled_indices]\n",
    "subset_categories = [documents[i]['metadata'].get('category', 'unknown') for i in sampled_indices]\n",
    "\n",
    "# Create a DataFrame for the heatmap\n",
    "similarity_df = pd.DataFrame(subset_similarity, \n",
    "                             index=subset_titles,\n",
    "                             columns=subset_titles)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "heatmap = sns.heatmap(similarity_df, annot=False, cmap='viridis', vmin=0, vmax=1)\n",
    "plt.title('Document Similarity Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"document_similarity_heatmap.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query-Document Similarity Visualization\n",
    "\n",
    "Let's visualize how different queries relate to our document corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# Define some sample queries\n",
    "sample_queries = [\n",
    "    \"How does HRV relate to recovery?\",\n",
    "    \"What are the best sleep optimization strategies?\",\n",
    "    \"How to monitor training load effectively?\",\n",
    "    \"What causes overtraining syndrome?\",\n",
    "    \"How does nutrition affect recovery?\"\n",
    "]\n",
    "\n",
    "# Generate embeddings for queries\n",
    "query_embeddings = embedder.embed_query(sample_queries)\n",
    "\n",
    "# Calculate similarity between queries and documents\n",
    "query_doc_similarity = cosine_similarity(query_embeddings, doc_embeddings)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "# Use the same sampled documents as before for consistency\n",
    "subset_query_similarity = query_doc_similarity[:, sampled_indices]\n",
    "query_similarity_df = pd.DataFrame(subset_query_similarity,\n",
    "                                  index=sample_queries,\n",
    "                                  columns=subset_titles)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.heatmap(query_similarity_df, annot=True, cmap='YlGnBu', vmin=0, vmax=1, fmt='.2f')\n",
    "plt.title('Query-Document Similarity Heatmap', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"query_document_similarity.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# For each query, show the top 3 most similar documents\n",
    "for i, query in enumerate(sample_queries):\n",
    "    # Get similarities for all documents\n",
    "    similarities = query_doc_similarity[i]\n",
    "    \n",
    "    # Get indices of top 5 most similar documents\n",
    "    top_indices = np.argsort(similarities)[::-1][:3]\n",
    "    \n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"Top 3 most similar documents:\")\n",
    "    for idx in top_indices:\n",
    "        print(f\"- {documents[idx]['title']} (Similarity: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. UMAP Visualization with Category Coloring\n",
    "\n",
    "UMAP often preserves both local and global structure better than t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_embeddings = reducer.fit_transform(doc_embeddings)\n",
    "\n",
    "# Update the DataFrame for plotting\n",
    "plot_df['umap_x'] = umap_embeddings[:, 0]\n",
    "plot_df['umap_y'] = umap_embeddings[:, 1]\n",
    "\n",
    "# Plot UMAP visualization\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.scatterplot(data=plot_df, x='umap_x', y='umap_y', hue='category', style='category', s=100, alpha=0.7)\n",
    "plt.title('UMAP Visualization of Document Embeddings by Category', fontsize=16)\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
    "plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Add annotations for a few points\n",
    "for i, row in plot_df.sample(min(10, len(plot_df))).iterrows():\n",
    "    plt.annotate(row['title'][:20] + '...', \n",
    "                 (row['umap_x'], row['umap_y']),\n",
    "                 xytext=(5, 5),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=8,\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"umap_visualization.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Document Clusters\n",
    "\n",
    "Let's use K-means clustering to identify natural groups in our document space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Determine optimal number of clusters using silhouette score\n",
    "silhouette_scores = []\n",
    "K_range = range(2, min(10, len(documents)))\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(doc_embeddings)\n",
    "    silhouette_avg = silhouette_score(doc_embeddings, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {k}, the silhouette score is {silhouette_avg:.3f}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, silhouette_scores, 'o-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Different Numbers of Clusters')\n",
    "plt.grid(True)\n",
    "plt.savefig(OUTPUT_DIR / \"silhouette_scores.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Choose optimal k (highest silhouette score)\n",
    "optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "# Apply K-means with optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(doc_embeddings)\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "plot_df['cluster'] = cluster_labels\n",
    "\n",
    "# Visualize clusters on UMAP projection\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.scatterplot(data=plot_df, x='umap_x', y='umap_y', hue='cluster', palette='tab10', s=100, alpha=0.7)\n",
    "plt.title(f'Document Clusters (K={optimal_k}) Visualized with UMAP', fontsize=16)\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"document_clusters.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Compare clusters with categories\n",
    "cluster_category_counts = pd.crosstab(plot_df['cluster'], plot_df['category'])\n",
    "print(\"\\nCluster-Category Distribution:\")\n",
    "display(cluster_category_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Embedding Space Analysis for a Specific Query\n",
    "\n",
    "Let's visualize how a specific query relates to the document space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "# Choose a specific query for detailed analysis\n",
    "focus_query = \"How does sleep quality affect HRV and recovery?\"\n",
    "focus_query_embedding = embedder.embed_query([focus_query])[0]\n",
    "\n",
    "# Calculate similarity to all documents\n",
    "similarities = cosine_similarity([focus_query_embedding], doc_embeddings)[0]\n",
    "\n",
    "# Add similarity scores to the DataFrame\n",
    "plot_df['query_similarity'] = similarities\n",
    "\n",
    "# Visualize on UMAP projection with similarity as color intensity\n",
    "plt.figure(figsize=(14, 10))\n",
    "scatter = plt.scatter(plot_df['umap_x'], plot_df['umap_y'], \n",
    "                      c=plot_df['query_similarity'], cmap='YlOrRd', \n",
    "                      s=100, alpha=0.8, edgecolors='k', linewidths=0.5)\n",
    "\n",
    "plt.colorbar(scatter, label='Similarity to Query')\n",
    "plt.title(f'Document Similarity to Query: \"{focus_query}\"', fontsize=16)\n",
    "plt.xlabel('UMAP Dimension 1', fontsize=12)\n",
    "plt.ylabel('UMAP Dimension 2', fontsize=12)\n",
    "\n",
    "# Annotate top 5 most similar documents\n",
    "top5_indices = np.argsort(similarities)[::-1][:5]\n",
    "for idx in top5_indices:\n",
    "    row = plot_df.iloc[idx]\n",
    "    plt.annotate(f\"{row['title'][:20]}... ({similarities[idx]:.2f})\", \n",
    "                 (row['umap_x'], row['umap_y']),\n",
    "                 xytext=(10, 10),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=9,\n",
    "                 bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", alpha=0.8),\n",
    "                 arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"query_similarity_map.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Print top 10 most similar documents\n",
    "print(f\"Top 10 documents most similar to query: '{focus_query}'\\n\")\n",
    "top10_indices = np.argsort(similarities)[::-1][:10]\n",
    "for i, idx in enumerate(top10_indices):\n",
    "    print(f\"{i+1}. {documents[idx]['title']} (Similarity: {similarities[idx]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comparing Embedding Quality\n",
    "\n",
    "Let's compare how well our embeddings capture semantic relationships by testing with related queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# Define semantically related queries\n",
    "related_queries = [\n",
    "    \"What is HRV?\",\n",
    "    \"How is heart rate variability measured?\",\n",
    "    \"What factors affect heart rate variability?\",\n",
    "    \"How does HRV relate to stress?\",\n",
    "    \"Can HRV predict overtraining?\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "related_embeddings = embedder.embed_query(related_queries)\n",
    "\n",
    "# Calculate similarity between queries\n",
    "query_similarity = cosine_similarity(related_embeddings)\n",
    "\n",
    "# Visualize query similarity\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(query_similarity, annot=True, cmap='Blues', vmin=0, vmax=1,\n",
    "            xticklabels=[q[:20] + '...' for q in related_queries],\n",
    "            yticklabels=[q[:20] + '...' for q in related_queries])\n",
    "plt.title('Semantic Similarity Between Related Queries', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"query_semantic_similarity.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've visualized and analyzed the embedding space of our document corpus. Key findings include:\n",
    "\n",
    "1. **Document Clustering**: We identified natural clusters in our document space that largely align with the document categories.\n",
    "\n",
    "2. **Query-Document Relationships**: We visualized how different queries relate to our documents, showing which documents are most semantically similar to specific queries.\n",
    "\n",
    "3. **Embedding Quality**: We evaluated the quality of our embeddings by examining how well they capture semantic relationships between related queries.\n",
    "\n",
    "These visualizations provide valuable insights into the behavior of our retrieval system and can help identify areas for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
